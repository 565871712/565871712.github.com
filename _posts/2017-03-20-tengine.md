---
layout: post
title: "tengine 环境搭建"
date: 2017-01-27
categories: nginx

---

### 什么是nginx
nginx是一个高性能的HTTP和反向代理服务器,聚焦于高性能，高并发和低内存消耗问题。并且具有多种web服务器功能特性：反向代理、负载均衡，缓存，访问控制，带宽控制，以及高效整合各种应用的能力，在高连接并发的情况下，Nginx是Apache服务器不错的替代品。能够支持高达 50,000 个并发连接数的响应。

### 什么是Tengine
Tengine是由淘宝网发起的Web服务器项目。它在Nginx的基础上，针对大访问量网站的需求，添加了很多高级功能和特性。Tengine的性能和稳定性已经在大型的网站如淘宝网，天猫商城等得到了很好的检验。它的最终目标是打造一个高效、稳定、安全、易用的Web平台。
从2011年12月开始，Tengine成为一个开源项目，Tengine团队在积极地开发和维护着它。Tengine团队的核心成员来自于淘宝、搜狗等互联网企业。Tengine是社区合作的成果，我们欢迎大家参与其中，贡献自己的力量。

### 为什么要用tengine

项目主要是运用了tengine的反向代理和负载均衡两个功能，对线上各个项目进行双主机运行，保证在某一个服务器出现故障之后服务还能够正常运行，减少tomcat压力。再打包上线时候也可以服务单个替换，逐个上线保证在对外服务不间断的情况下进行版本更新。同时利用tengine对上传文件、静态文件的缓存以及对页面的压缩、对js css请求的合并加快用户的访问速度，利用访问速度限时减小ddos攻击对项目的损失。

### 新增特性
详见[官方网站](http://tengine.taobao.org)

### 安装：

tengine安装及使用说明

1、 系统采用centos 6.5 版本
2、安装前需要事先安装软件所需的环境 

```
[root@hzq ~]#yum install -y jemalloc jemalloc-devel
[root@hzq ~]#yum install -y zlib zlib-devel
[root@hzq ~]#yum install -y pcre pcre-devel
[root@hzq ~]#yum install -y openssl openssl-devel
```
3、 环境安装完毕后安装tengine

```
[root@hzq ~]#cd /home/tengine
[root@hzq ~]#tar -zxvf tengine-2.1.2.tar.gz
[root@hzq ~]#cd tengine-2.1.2
[root@hzq ~]# ./configure --prefix=/opt/nginx --with-http_stub_status_module --with-http_ssl_module --with-http_gzip_static_module --with-http_stub_status_module --with-http_upstream_check_module --with-http_gzip_static_module --with-http_ssl_module --with-http_v2_module --with-http_concat_module --with-jemalloc --with-http_spdy_module  

[root@hzq ~]#make && make install
[root@hzq ~]#cd /opt/nginx
[root@hzq ~]#./sbin/nginx
```
4、配置文件conf/nginx.conf

参照nginx正常配置文件写即可。

输入代码检查是否支持加速    查看是否生效

[root@hzq ~]#lsof -n | grep jemalloc

5、相关语法

```
sbin/nginx -t  语法校验
sbin/nginx -s reload  语法校验
sbin/nginx -s stop 停止运行
sbin/nginx -V sbin/nginx -m 查看已加载的库文件
```

### nginx.conf 相关参数设置

```
#用户及用户组
#user  nobody;
#工作进程，根据硬件调整，大于等于cpu核数 小于cpu合数的2倍
worker_processes  auto;
worker_cpu_affinity auto;
#更改worker进程的最大打开文件数限制
worker_rlimit_nofile 65535;

#错误日志(将不同的日志等级、记录到不同的文件中)
#error_log  logs/error.log;
error_log  logs/error.log  notice;
#error_log  logs/error.log  info;

#pid        logs/nginx.pid;


events {
    #每一个worker的连接数
    worker_connections  1024;
    #SO_REUSEPORT 能让tengnix性能提升三倍，但需要linux内核版本3.9才支持
    reuse_port on;

}

# load modules compiled as Dynamic Shared Object (DSO)
#
dso {
    #load ngx_http_fastcgi_module.so;
    #load ngx_http_rewrite_module.so;
   # load ngx_http_sysguard_module.so;
}

http {
    #include 用户加载另外的配置文件,例如其它配置内容
    include       mime.types;
    default_type  application/octet-stream;
    #关闭在错误页面中的nginx版本数字
    server_tokens off;    
    charset  utf-8; 
    #限制并发连接数以及下载带宽 
    limit_conn_zone $binary_remote_addr zone=addr:10m;
    #limit_conn addr 100;   

    #用于合并多个文件在一个响应报文中
    concat on;
    concat_types text/css text/html application/javascript;
    concat_max_files 30;

    # 命名为main的日志格式
    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';
    # 访问的日志
    access_log  logs/access.log  main;

#【文件模块：主要是一些静态文件的传送设置】
    sendfile        on; #开启文件从硬盘到网络的传输，不需要通过缓存（减少IO，平缓硬盘和网络的处理速度）
    #tcp_nopush     on; #此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用

#【响应设置，缓存和响应】
    client_max_body_size 50m;           #客户端请求的请求体大小，上传文件的大小
    client_header_buffer_size 4k;       #客户端请求头部的缓冲区大小
    client_body_buffer_size 256k;       #客服端请求体缓存大小
    large_client_header_buffers 8 128k; #客户请求头的最大缓冲大小
    client_header_timeout 3m;           #请求头超时
    client_body_timeout 3m;            #请求体超时
    reset_timeout_connection            #关闭不响应的客户端连接。这将会释放那个客户端所占有的内存空间
    send_timeout 3m;                    #客服端响应超时
  #  keepalive_timeout  65;              #nginx和client的连接超时


    #可以压缩访问网页,将网页体积减少为之前的百分之三十
    gzip on; 
    gzip_proxied any;       #允许或者禁止压缩基于请求和响应的响应流
    gzip_min_length  1k;    #最小的压缩文件，小于这个不压缩
    gzip_buffers    4 16k; 
    gzip_http_version 1.1; 
    gzip_comp_level 2;      #压缩等级（1-9）
    gzip_types       text/plain application/x-javascript text/css application/xml; 
    gzip_vary on; 

#【反向代理】
########## 响应时间 ######################
    proxy_connect_timeout 75s;      #nginx跟后端服务器请求时间
    proxy_rend_timeout 75s;     #连接后，等候后端服务器响应时间处理时间。
    proxy_send_timeout 75s;     #连接成功后，发送数据到后端服务器的时间
########## 响应缓存 ######################
    proxy_buffer_size 64k;              #代理服务器(nginx)保存用户头的缓冲区
    proxy_buffers 4 32k;                #proxy_buffers缓冲区，网页平均在32k以下
    proxy_busy_buffers_size 64k;        #高负荷下缓冲大小（proxy_buffers*2）
    proxy_temp_file_write_size 64k;    #设定缓存文件大小，大于这个值，将从后端服务器传送，不用通过nginx缓存
    proxy_ignore_client_abort on;       #如果客户端断开请求,也保持与后端服务器的连接，防止服务器出现BUG
################设置传送给后台服务器的请求头(主要是为了session) #####
    proxy_set_header Host $host;                #表示客户端请求头部中的Host字段
    proxy_set_header X-Real-IP $remote_addr;    #客户端IP地址
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;    #设置头转发

    #让404报错进入max_fails计数 
    proxy_next_upstream  http_404 http_502;
    upstream resinServer{ 
         consistent_hash $remote_addr;
        server   localhost:8081 weight=1  max_fails=3 fail_timeout=60s;
        server   localhost:8082 weight=1  max_fails=3 fail_timeout=60s;
        server   localhost:8083 weight=1  max_fails=3 fail_timeout=60s;
        server   localhost:8084 weight=1  max_fails=3 fail_timeout=60s;
         check interval=3000 rise=2 fall=5 timeout=1000 type=http;
          check_http_send "HEAD / HTTP/1.0\r\n\r\n";
            check_http_expect_alive http_2xx http_3xx;


    }

    upstream wsbackend {
      server 192.168.1.49:2048;
    }

    map $http_upgrade $connection_upgrade {
        default upgrade;
        ''      close;
    }

    server {
        listen       80 ssl http2 spdy default_server; 
        server_name  localhost;
        #限制每个请求对后端服务器访问的最大尝试次数
        proxy_upstream_tries 20;
        proxy_set_header Host $host;

        #charset koi8-r;

        #access_log  logs/host.access.log  main;

        location / {
            root   html;
            index  index.html index.htm;
            proxy_buffering off;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_pass http://resinServer;
            trim on;
            trim_js on;
            trim_css on;
            expires_by_types       24h text/html;
            expires_by_types       modified +24h text/xml;
            expires_by_types       @15h30m text/xml;
            expires_by_types       0 text/xml;
            expires_by_types       -1 text/xml;
            expires_by_types       epoch text/xml;
        }
        location /wsbackend {
            proxy_pass http://wsbackend;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header Host $host;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection  "upgrade";
        }

        location /status {
          check_status;
          access_log off;
          #allow IP;
          #deny all;
        }

        #加入对css js的缓存
        location ~ .*＼.(css|js)(.*) {
          expires 5h;
        }

        #加入对图片文件的缓存
        location ~ \.(gif|jpg|jpeg|png|bmp|ico)$ { expires 30d; } 

        #error_page  404              /404.html;

        # redirect server error pages to the static page /50x.html
        #
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }

        # proxy the PHP scripts to Apache listening on 127.0.0.1:80
        #
        #location ~ \.php$ {
        #    proxy_pass   http://127.0.0.1;
        #}

        # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
        #
        #location ~ \.php$ {
        #    root           html;
        #    fastcgi_pass   127.0.0.1:9000;
        #    fastcgi_index  index.php;
        #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;
        #    include        fastcgi_params;
        #}

        # deny access to .htaccess files, if Apache's document root
        # concurs with nginx's one
        #
        #location ~ /\.ht {
        #    deny  all;
        #}
    }


    # another virtual host using mix of IP-, name-, and port-based configuration
    #
    #server {
    #    listen       8000;
    #    listen       somename:8080;
    #    server_name  somename  alias  another.alias;

    #    location / {
    #        root   html;
    #        index  index.html index.htm;
    #    }
    #}


    # HTTPS server
    #
    #server {
    #    listen       443 ssl;
    #    server_name  localhost;

    #    ssl_certificate      cert.pem;
    #    ssl_certificate_key  cert.key;

    #    ssl_session_cache    shared:SSL:1m;
    #    ssl_session_timeout  5m;

    #    ssl_ciphers  HIGH:!aNULL:!MD5;
    #    ssl_prefer_server_ciphers  on;

    #    location / {
    #        root   html;
    #        index  index.html index.htm;
    #    }
    #}

}
```

### 负载均衡策略

在nginx中支持的负载均衡策略如下：

* 轮询加权策略（Round-Robin）：在轮询模策略中，要求应用服务器是分布式的

```
http {
   upstream myapp1 {           #服务器组，组名：myapp1
       server srv1.example.com;  #web应用服务器1
       server srv2.example.com;  #web应用服务器2
       server srv3.example.com;  #web应用服务器3
    }
    server {
       listen 80;
       location / {
           proxy_pass http://myapp1;          #客户端访问的URL
       }
    }
}
以上是最简单的Nginx负载均衡配置。在upstream myapp1中有3个应用服务器实例，当负载均衡中没有指定配置负载策略时，默认是使用轮询权重策略。所有请求都是代理给服务器组myapp1，Nginx应用http负载均衡到分布式请求中。
在Nginx反向代理负载均衡的扩展包括：http，https，FastCGI，uwsgi，SCGI和缓存。
配置负载均衡
配置https负载均衡代替http，只使用“https”作为协议就可以了。
当设置负载均衡为FastCGI，uwsgi，SCGI，或缓存，指令分别使用fastcgi_pass，uwsgi_pass，scgi_pass，和memcached_pass。
如果可以把加权轮询算法分为先深搜索和先广搜索，那么nginx采用的是先深搜索算法，即将首先将请求都分给高权重的机器，直到该机器的权值降到了比其他机器低，才开始将请求分给下一个高权重的机器；第二，当所有后端机器都down掉时，nginx会立即将所有机器的标志位清成初始状态，以避免造成所有的机器都处在timeout的状态，从而导致整个前端被夯住。
```

* 最少连接策略（Least-Connected）：下一个请求是分配给最少的活动连接数服务器。

```
upstream myapp1 {                     #服务器组，组名：myapp1
       least_conn;                  #least_conn;最少连接策略
       server srv1.example.com;       #web应用服务器1
       server srv2.example.com;       #web应用服务器2
       server srv3.example.com;       #web应用服务器3
}
最少连接允许控制加载应用实例，更多适合在一些花费比较长时间去完成请求的一个场景中。
用最少连接负载均衡，Nginx会尽量不要求过载繁忙的应用服务器去执行请求，分配新的请求给一个不太忙碌的服务器代替执行。
最少连接负载均衡在Nginx中被激活时，least_conn指令被用来作为服务器群组配置的一个部分。
```

* IP哈希策略（IP-Hash）：一个哈希函数用来决定那个服务器被选择作为下一个请求处理的服务器（基于客户端的IP地址）。

```
配置IP哈希负载均衡，只需要添加ip_hash指令指向服务器(uptream) 组配置：
upstream myapp1 {
   ip_hash;
   server srv1.example.com;
   server srv2.example.com;
   server srv3.example.com;
}
每个客户端请求都有可能发送到不同的服务器，不能保证同一个客户端总是指向同一个服务器。如果一个客户端必须要跟服务器的会话关联在一起的时候，可以使用IP哈希负载均衡缓存策略。
通过获取客户端额IP地址，经过哈希函数的计算得到一个值，利用该值对服务器的列表大小进行取模运算，得到的值就是处理客户端请求的服务器序号。采用IP哈希负载均衡策略，的优点是，同一个客户端的IP地址，每次发送的请求都是指向同一台服务器进行处理。这种方式确保来自同一个客户端请求总是指向同一个服务器除非这个服务是无效的。
举例子说明：
例如一个系统的会话存储用户信息，每次将请求发送到服务器，服务器都会从会话中获取数据。但在负载均衡环境中，每次客户端的每次请求都可能由不同的服务器处理，所以可能出现无法获取的到客户端的会话数据（由于会话数据是保存在服务器的内存中）。
```
* 权重策略

```
使用服务器权重策略，它也有可能影响到Nginx负载均衡算法。
在上面的例子中，服务器权重没有配置，意味着所有指定的服务器都被视为同等资格的一个特定负载均衡策略。尤其是轮询策略，它也意味着差不多平等地分配请求给服务器，并且快速平均地处理请求。
 
当权重参数被指定在一个服务器时，权重作为负载均衡决策的部分。
upstream myapp1 {
       server srv1.example.com weight=3;
       server srv2.example.com;
       server srv3.example.com;
}
在这个配置中，每5个请求都分配给应用服务器实例如下：
3个请求将分配到serv1中，1个请求分配给srv2中，而另外1个请求则分配个srv3中。
在最近的Nginx版本中，它同样可以与最少连接和IP哈希策略一样去使用权重策略。
```

### 总结

策略|优点|缺点
-|-|-
轮询策略|如果希望每个服务器都能平均处理客户端请求可使用轮询策略|不支持会话管理，另外，假设有5个客户端请求，有2台服务器处理请求，某一台服务器处理请求时消耗资源比较大，每次都接到消耗资源比较大的请求，那么该服务器处理能力就会下降。
IP哈希策略|使用该策略，服务器可能不会平均处理每个请求。假设有5个客户端请求，那么通过计算出哈希值后，可能都是由一台服务器处理。其它的服务器可能没有请求需要处理。|虽然某个服务器的连接数较少，但处理请求时间较长，这时候再接受请求处理，可能影响到时间效率的问题。
最少连接策略|系统把新连接分配给当前连接数目最少的服务器。该算法在各个服务器运算能力基本相似的环境中非常有效。此负载均衡策略适合请求处理时间长短不一造成服务器过载的情况。|虽然某个服务器的连接数较少，但处理请求时间较长，这时候再接受请求处理，可能影响到时间效率的问题。
权重策略|如果服务器的硬件等级差别比较大，那么配置高的服务器可分配较高权重，以便处理更多的请求。而配置低的服务器可接受少量请求。|如果服务器的硬件等级一样不太适合使用该策略。

### 安装备注

consistent_hash $request_uri; 一致性hash模块
如设置此参数则增加tengine粘性，相同用户的请求汇集到同一服务器

如果出现缺少动态库情况
http://blog.csdn.net/rznice/article/details/50857220

重启nginx后丢失nginx.pid, 如果在kill nginx进程的时候无法启动则执行以下方法
./nginx -c /alidata/server/nginx/conf/nginx.conf

### 环境优化
[服务器的参数调优](http://colobu.com/2015/05/22/implement-C1000K-servers-by-spray-netty-undertow-and-node-js/)

	

